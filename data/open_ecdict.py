# -*- coding: utf-8 -*-
import os
import re
import json
import time

# --- 1. é…ç½®åŒºåŸŸ ---
# ä¸»è¯å¤´æ–‡ä»¶
HW_FILE = 'ODE è¯å¤´.txt'

# æ•°æ®æºæ–‡ä»¶ (æŒ‰fallbacké¡ºåº)
SOURCE_FILES = {
    1: 'è‹±è¯­ä¸“ä¸šå››å…«çº§è¯æ±‡è¡¨.txt',
    2: 'ç°ä»£è‹±æ±‰è¯å…¸.txt',
    3: 'OALD8_ç®€ä½“ä¸­æ–‡é‡Šä¹‰.txt',
    4: 'oxford_dict_result.txt',
    5: 'extracted_from_ODE.txt'
}

# è¾“å‡ºæ–‡ä»¶
TXT_OUTPUT_FILE = 'final_vocabulary.txt'
JSON_OUTPUT_FILE = 'final_vocabulary.json'

# ä¸­é—´ç´¢å¼•æ–‡ä»¶ (ç”¨äºç¼“å­˜å’Œæ£€æŸ¥)
INDEX_FILES = {
    1: 'index_1.json',
    2: 'index_2.json',
    3: 'index_3.json',
    4: 'index_4.json',
    5: 'index_5.json'
}


# --- 2. è¾…åŠ©å‡½æ•° ---

def save_index_to_json(data, filename):
    """å°†å­—å…¸æˆ–åˆ—è¡¨æ•°æ®ä¿å­˜ä¸ºæ ¼å¼åŒ–çš„JSONæ–‡ä»¶ã€‚"""
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        print(f"âœ… æ•°æ®å·²æˆåŠŸä¿å­˜åˆ°: {filename}")
    except Exception as e:
        print(f"âŒ ä¿å­˜åˆ° {filename} æ—¶å‡ºé”™: {e}")

def extract_pron_and_def_from_brackets(text):
    """ä»æ–‡æœ¬ä¸­æå–æ–¹æ‹¬å· [...] å†…çš„éŸ³æ ‡ã€‚"""
    pattern = re.compile(r"(\[.*?\])")
    match = pattern.search(text)
    if match:
        pron = match.group(1)
        definition = text.replace(match.group(0), '').strip()
        return pron, definition
    return None, text.strip()


# --- 3. ä¸“ç”¨ç´¢å¼•æ„å»ºå‡½æ•° ---

def build_index_from_file_1(filepath):
    """ä¸ºæºæ–‡ä»¶1æ„å»ºç´¢å¼• (éŸ³æ ‡æ ¼å¼: [...])ã€‚"""
    print(f"--- æ­£åœ¨ä¸º {filepath} æ„å»ºç´¢å¼• ---")
    index = {}
    headword_pattern = re.compile(r"^(\*?[\w\s\.-]+?)\s+(.*)")
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line: continue
                match = headword_pattern.match(line)
                if match:
                    headword = match.group(1).replace('*', '').strip()
                    full_def = match.group(2).strip()
                    pron, definition = extract_pron_and_def_from_brackets(full_def)
                    if headword:
                        if headword in index:
                            index[headword]['def'] += f" | {definition}"
                            if not index[headword]['pron'] and pron:
                                index[headword]['pron'] = pron
                        else:
                            index[headword] = {"pron": pron, "def": definition}
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ–‡ä»¶æœªæ‰¾åˆ° {filepath}"); return None
    print(f"æ„å»ºå®Œæˆï¼Œå…±ç´¢å¼• {len(index)} ä¸ªè¯æ¡ã€‚")
    return index

def build_index_from_file_2(filepath):
    """ä¸ºæºæ–‡ä»¶2æ„å»ºç´¢å¼• (éŸ³æ ‡æ ¼å¼: /.../ -> [...])ã€‚"""
    print(f"--- æ­£åœ¨ä¸º {filepath} æ„å»ºç´¢å¼• ---")
    index = {}
    headword_pattern = re.compile(r"^([\w\s'-]+?)\s*((?:/|\s{2,}).*)")
    pron_pattern = re.compile(r"\/(.*?)\/")
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line: continue
                match = headword_pattern.match(line)
                if match:
                    headword, full_def = match.group(1).strip(), match.group(2).strip()
                    pron, definition = None, full_def
                    pron_match = pron_pattern.search(full_def)
                    if pron_match:
                        pron = f"[{pron_match.group(1)}]"
                        definition = full_def.replace(pron_match.group(0), '').strip()
                    if headword:
                        if headword in index:
                            index[headword]['def'] += f" | {definition}"
                            if not index[headword]['pron'] and pron:
                                index[headword]['pron'] = pron
                        else:
                            index[headword] = {"pron": pron, "def": definition}
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ–‡ä»¶æœªæ‰¾åˆ° {filepath}"); return None
    print(f"æ„å»ºå®Œæˆï¼Œå…±ç´¢å¼• {len(index)} ä¸ªè¯æ¡ã€‚")
    return index

def build_index_from_file_3(filepath):
    """ä¸ºæºæ–‡ä»¶3æ„å»ºç´¢å¼• (éŸ³æ ‡æ ¼å¼: [...])ã€‚"""
    print(f"--- æ­£åœ¨ä¸º {filepath} æ„å»ºç´¢å¼• ---")
    index = {}
    headword_pattern = re.compile(r"^([\w\s'-]+?)\s*((?:\[|\s{2,}).*)")
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line: continue
                match = headword_pattern.match(line)
                if match:
                    headword, full_def = match.group(1).strip(), match.group(2).strip()
                    pron, definition = extract_pron_and_def_from_brackets(full_def)
                    if headword:
                        if headword in index:
                            index[headword]['def'] += f" | {definition}"
                            if not index[headword]['pron'] and pron:
                                index[headword]['pron'] = pron
                        else:
                            index[headword] = {"pron": pron, "def": definition}
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ–‡ä»¶æœªæ‰¾åˆ° {filepath}"); return None
    print(f"æ„å»ºå®Œæˆï¼Œå…±ç´¢å¼• {len(index)} ä¸ªè¯æ¡ã€‚")
    return index

def build_index_from_file_4(filepath):
    """ä¸ºæºæ–‡ä»¶4æ„å»ºç´¢å¼• (éŸ³æ ‡åœ¨ç‹¬ç«‹è¡Œ)ã€‚"""
    print(f"--- æ­£åœ¨ä¸º {filepath} æ„å»ºç´¢å¼• ---")
    index = {}
    try:
        with open(filepath, 'r', encoding='utf-8') as f: content = f.read()
        entries = re.split(r'\n\s*\n', content)
        for entry in entries:
            entry = entry.strip()
            if not entry: continue
            lines = [l.strip() for l in entry.split('\n')]
            headword = lines[0]
            pron, definition_lines = None, lines[1:]
            if len(lines) > 1 and lines[1].startswith('/') and lines[1].endswith('/'):
                pron_content = lines[1].strip(' /')
                pron = f"[{pron_content}]"
                definition_lines = lines[2:]
            definition = ' '.join(definition_lines)
            if headword and headword not in index:
                index[headword] = {"pron": pron, "def": definition}
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ–‡ä»¶æœªæ‰¾åˆ° {filepath}"); return None
    print(f"æ„å»ºå®Œæˆï¼Œå…±ç´¢å¼• {len(index)} ä¸ªè¯æ¡ã€‚")
    return index

def build_index_from_file_5(filepath):
    """ä¸ºæºæ–‡ä»¶5æ„å»ºç´¢å¼• (éŸ³æ ‡æ ¼å¼: /.../ -> [...])ã€‚"""
    print(f"--- æ­£åœ¨ä¸º {filepath} æ„å»ºç´¢å¼• ---")
    index = {}
    separator = 'â‡’'
    pron_pattern = re.compile(r"\/(.*?)\/")
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or separator not in line: continue
                parts = line.split(separator, 1)
                headword, full_def = parts[0].strip(), parts[1].strip()
                pron, definition = None, full_def
                pron_match = pron_pattern.search(full_def)
                if pron_match:
                    pron = f"[{pron_match.group(1)}]"
                    definition = full_def.replace(pron_match.group(0), '').strip()
                if headword:
                    if headword in index:
                        index[headword]['def'] += f" | {definition}"
                        if not index[headword]['pron'] and pron:
                            index[headword]['pron'] = pron
                    else:
                        index[headword] = {"pron": pron, "def": definition}
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ–‡ä»¶æœªæ‰¾åˆ° {filepath}"); return None
    print(f"æ„å»ºå®Œæˆï¼Œå…±ç´¢å¼• {len(index)} ä¸ªè¯æ¡ã€‚")
    return index

# --- 4. ä¸»ç¨‹åº ---
def main():
    """ä¸»ç¨‹åºï¼Œåè°ƒç´¢å¼•æ„å»ºã€æ•°æ®åˆå¹¶å’Œæ–‡ä»¶è¾“å‡ºã€‚"""
    total_start_time = time.time()

    # é˜¶æ®µä¸€: æ„å»ºæ‰€æœ‰æ•°æ®æºçš„ç´¢å¼•
    print("===== é˜¶æ®µä¸€: å¼€å§‹æ„å»ºç´¢å¼• =====")
    indexes = {}
    tasks = [
        # (1, build_index_from_file_1, SOURCE_FILES[1], INDEX_FILES[1]),
        (2, build_index_from_file_2, SOURCE_FILES[2], INDEX_FILES[2]),
        (3, build_index_from_file_3, SOURCE_FILES[3], INDEX_FILES[3]),
        (4, build_index_from_file_4, SOURCE_FILES[4], INDEX_FILES[4]),
        (5, build_index_from_file_5, SOURCE_FILES[5], INDEX_FILES[5]),
    ]
    for num, build_func, src_file, idx_file in tasks:
        idx = build_func(src_file)
        if idx is not None:
            indexes[num] = idx
            save_index_to_json(idx, idx_file)
    print("===== ç´¢å¼•æ„å»ºé˜¶æ®µå®Œæˆ =====\n")

    # é˜¶æ®µäºŒ: è¯»å–ä¸»è¯å¤´åˆ—è¡¨ï¼Œå¹¶åˆå¹¶æ•°æ®
    print("===== é˜¶æ®µäºŒ: å¼€å§‹åˆå¹¶è¯æ±‡è¡¨ =====")
    try:
        with open(HW_FILE, 'r', encoding='utf-8') as f:
            headword_lines = [line.strip() for line in f if line.strip()]
        print(f"ä» {HW_FILE} è¯»å–äº† {len(headword_lines)} è¡Œã€‚")
    except FileNotFoundError:
        print(f"âŒ è‡´å‘½é”™è¯¯: è¯å¤´æ–‡ä»¶ {HW_FILE} æœªæ‰¾åˆ°ã€‚ç¨‹åºç»ˆæ­¢ã€‚"); return

    final_data_list = []
    found_count, redirect_count = 0, 0
    with open(TXT_OUTPUT_FILE, 'w', encoding='utf-8') as f_out:
        for line in headword_lines:
            # æ£€æŸ¥æ˜¯å¦ä¸ºè·³è½¬é“¾æ¥
            if 'â–º@@@LINK' in line:
                redirect_count += 1
                f_out.write(f"{line}\n\n")
                parts = line.split('â–º', 1)
                hw, link_def = parts[0].strip(), 'â–º' + parts[1].strip()
                entry_data = {"headword": hw, "pron": None, "def": link_def, "source": "redirect"}
            else:
                hw, found_entry, source_num = line, None, 0
                # æŒ‰é¡ºåºåœ¨ç´¢å¼•ä¸­æŸ¥æ‰¾
                for i in sorted(indexes.keys()):
                    if indexes.get(i) and hw in indexes[i]:
                        found_entry = indexes[i][hw]
                        source_num = i
                        break
                
                if found_entry:
                    found_count += 1
                    pron_str = found_entry.get('pron') or ''
                    def_str = found_entry.get('def', '')

                    if pron_str:
                        full_def_str = f"{pron_str} â€» {def_str}".strip()
                    else:
                        full_def_str = def_str
                    
                    f_out.write(f"{hw} â‡’ {full_def_str} ã€‡ã€ˆ{source_num}ã€‰\n\n")
                    entry_data = {"headword": hw, "pron": found_entry.get('pron'), "def": def_str, "source": source_num}
                else:
                    f_out.write(f"{hw} <Not Found>\n\n")
                    entry_data = {"headword": hw, "pron": None, "def": None, "source": 0}
            
            final_data_list.append(entry_data)
    print("===== åˆå¹¶é˜¶æ®µå®Œæˆ =====\n")

    # é˜¶æ®µä¸‰: è¾“å‡ºæœ€ç»ˆçš„JSONæ–‡ä»¶
    print("===== é˜¶æ®µä¸‰: ç”ŸæˆJSONè¾“å‡ºæ–‡ä»¶ =====")
    save_index_to_json(final_data_list, JSON_OUTPUT_FILE)
    print("===== JSONç”Ÿæˆé˜¶æ®µå®Œæˆ =====\n")

    # æœ€ç»ˆæŠ¥å‘Š
    total_end_time = time.time()
    total_entries = len(headword_lines)
    not_found_count = total_entries - found_count - redirect_count
    print("===== å¤„ç†å®Œæˆ =====")
    print(f"ğŸ‰ å…¨éƒ¨ä»»åŠ¡ç»“æŸï¼")
    print(f"    - æ€»å¤„ç†è¯å¤´æ•°: {total_entries}")
    print(f"    - æˆåŠŸåŒ¹é…é‡Šä¹‰: {found_count}")
    print(f"    - è·³è½¬é“¾æ¥è¯æ¡: {redirect_count}")
    print(f"    - æœªèƒ½åŒ¹é…è¯æ¡: {not_found_count}")
    print("-" * 20)
    print(f"    - TXT è¯æ±‡è¡¨å·²ç”Ÿæˆ: {TXT_OUTPUT_FILE}")
    print(f"    - JSON è¯æ±‡è¡¨å·²ç”Ÿæˆ: {JSON_OUTPUT_FILE}")
    print(f"    - ä¸­é—´ç´¢å¼•æ–‡ä»¶å·²ç”Ÿæˆ (index_*.json)")
    print("-" * 20)
    print(f"    - æ€»è€—æ—¶: {total_end_time - total_start_time:.2f} ç§’")

if __name__ == '__main__':
    main()